Configuration parameters at station PORT ELIZABETH AWS: {'Activation': 'relu', 'Epochs': 40, 'Patience': 5, 'Loss': 'MSE', 'Forecast Horizon': 24, 'Batch Size': 64, 'Lag': 48, 'Dropout': 0.3, 'lr': 0.01, 'Batch Norm': False, 'Weight Norm': False, 'Layer Norm': True, 'Padding': 'causal', 'Kernels': 2, 'Dilations': [1, 2, 4, 8, 16, 32, 64], 'Filters': 64, 'Layers': 2} with MSE =0.036164139479474826
Configuration parameters at station PORT ELIZABETH AWS: {'Activation': 'relu', 'Epochs': 40, 'Patience': 5, 'Loss': 'MSE', 'Forecast Horizon': 24, 'Batch Size': 64, 'Lag': 24, 'Dropout': 0.4, 'lr': 0.01, 'Batch Norm': False, 'Weight Norm': False, 'Layer Norm': True, 'Padding': 'causal', 'Kernels': 2, 'Dilations': [1, 2, 4, 8, 16, 32, 64], 'Filters': 32, 'Layers': 2} with MSE =0.03740403307981801
Configuration parameters at station PORT ELIZABETH AWS: {'Activation': 'relu', 'Epochs': 40, 'Patience': 5, 'Loss': 'MSE', 'Forecast Horizon': 24, 'Batch Size': 64, 'Lag': 48, 'Dropout': 0.3, 'lr': 0.01, 'Batch Norm': False, 'Weight Norm': False, 'Layer Norm': True, 'Padding': 'causal', 'Kernels': 2, 'Dilations': [1, 2, 4, 8, 16, 32, 64], 'Filters': 32, 'Layers': 1} with MSE =0.03223113221989788
Configuration parameters at station PORT ELIZABETH AWS: {'Activation': 'relu', 'Epochs': 40, 'Patience': 5, 'Loss': 'MSE', 'Forecast Horizon': 24, 'Batch Size': 64, 'Lag': 24, 'Dropout': 0.3, 'lr': 0.01, 'Batch Norm': False, 'Weight Norm': False, 'Layer Norm': True, 'Padding': 'causal', 'Kernels': 2, 'Dilations': [1, 2, 4, 8, 16, 32, 64], 'Filters': 64, 'Layers': 2} with MSE =0.038381296118042876
Configuration parameters at station PORT ELIZABETH AWS: {'Activation': 'relu', 'Epochs': 40, 'Patience': 5, 'Loss': 'MSE', 'Forecast Horizon': 24, 'Batch Size': 64, 'Lag': 24, 'Dropout': 0.3, 'lr': 0.01, 'Batch Norm': False, 'Weight Norm': False, 'Layer Norm': True, 'Padding': 'causal', 'Kernels': 2, 'Dilations': [1, 2, 4, 8, 16, 32, 64], 'Filters': 128, 'Layers': 1} with MSE =0.029169081220391812
Best parameters found at station PORT ELIZABETH AWS: {'Activation': 'relu', 'Epochs': 40, 'Patience': 5, 'Loss': 'MSE', 'Forecast Horizon': 24, 'Batch Size': 64, 'Lag': 24, 'Dropout': 0.3, 'lr': 0.01, 'Batch Norm': False, 'Weight Norm': False, 'Layer Norm': True, 'Padding': 'causal', 'Kernels': 2, 'Dilations': [1, 2, 4, 8, 16, 32, 64], 'Filters': 128, 'Layers': 1} with MSE =0.029169081220391812
